{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing tarining Dataset\n",
    "dataset = pd.read_csv('tcd-ml-1920-group-income-train.csv',low_memory=False)\n",
    "dataset = dataset.drop('Instance',axis=1)\n",
    "#dataset = dataset.drop('Wears Glasses',axis=1)\n",
    "#dataset = dataset.drop('Hair Color',axis=1)\n",
    "#dataset = dataset.drop('Gender',axis=1)\n",
    "#data_raw = dataset.drop(['Profession','Size of City'],axis=1)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning training dataset\n",
    "dataset['Housing Situation']=dataset['Housing Situation'].replace('0','nA')\n",
    "dataset['Satisfation with employer']=dataset['Satisfation with employer'].fillna('unknown')\n",
    "dataset['Gender'] = dataset['Gender'].fillna('unknown')\n",
    "dataset['Gender']=dataset['Gender'].replace('0','unknown')\n",
    "dataset['Profession']=dataset['Profession'].fillna('unknown')\n",
    "dataset['University Degree']=dataset['University Degree'].fillna('unknown')\n",
    "dataset['University Degree']=dataset['University Degree'].replace('0','unknown')\n",
    "dataset['Year of Record']=dataset['Year of Record'].fillna(dataset['Year of Record'].median())\n",
    "dataset=dataset.drop('Hair Color',axis=1)\n",
    "dataset['Work Experience in Current Job [years]']=dataset['Work Experience in Current Job [years]'].replace('#NUM!',-1)\n",
    "dataset['Work Experience in Current Job [years]']=pd.to_numeric(dataset['Work Experience in Current Job [years]'])\n",
    "dataset['Work Experience in Current Job [years]']=dataset['Work Experience in Current Job [years]'].replace(-1,dataset['Work Experience in Current Job [years]'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing test dataset\n",
    "test3 = pd.read_csv(\"tcd-ml-1920-group-income-test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning test data\n",
    "test3['Housing Situation']=test3['Housing Situation'].replace('0','nA')\n",
    "test3['Satisfation with employer']=test3['Satisfation with employer'].fillna('unknown')\n",
    "test3['Gender'] = test3['Gender'].fillna('unknown')\n",
    "test3['Gender']=test3['Gender'].replace('0','unknown')\n",
    "test3['Profession']=test3['Profession'].fillna('unknown')\n",
    "test3['University Degree']=test3['University Degree'].fillna('unknown')\n",
    "test3['University Degree']=test3['University Degree'].replace('0','unknown')\n",
    "test3['Year of Record']=test3['Year of Record'].fillna(dataset['Year of Record'].median())\n",
    "test3=test3.drop('Hair Color',axis=1)\n",
    "test3['Work Experience in Current Job [years]']=test3['Work Experience in Current Job [years]'].replace('#NUM!',-1)\n",
    "test3['Work Experience in Current Job [years]']=pd.to_numeric(test3['Work Experience in Current Job [years]'])\n",
    "test3['Work Experience in Current Job [years]']=test3['Work Experience in Current Job [years]'].replace(-1,dataset['Work Experience in Current Job [years]'].median())\n",
    "test3['Country'] = test3['Country'].fillna('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#target encoding\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    \n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target encode\n",
    "trn, sub = target_encode(trn_df[\"Housing Situation\"], \n",
    "                         sub_df[\"Housing Situation\"], \n",
    "                         target=trn_df['Total Yearly Income [EUR]'], \n",
    "                         min_samples_leaf=100,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.01)\n",
    "trn.head(10)\n",
    "trn_df['Housing Situation'] = trn\n",
    "sub_df['Housing Situation'] = sub\n",
    "trn, sub = target_encode(trn_df[\"Satisfation with employer\"], \n",
    "                         sub_df[\"Satisfation with employer\"], \n",
    "                         target=trn_df['Total Yearly Income [EUR]'], \n",
    "                         min_samples_leaf=100,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.01)\n",
    "trn.head(10)\n",
    "trn_df[\"Satisfation with employer\"] = trn\n",
    "sub_df[\"Satisfation with employer\"] = sub\n",
    "trn, sub = target_encode(trn_df[\"Gender\"], \n",
    "                         sub_df[\"Gender\"], \n",
    "                         target=trn_df['Total Yearly Income [EUR]'], \n",
    "                         min_samples_leaf=100,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.01)\n",
    "trn.head(10)\n",
    "trn_df[\"Gender\"] = trn\n",
    "sub_df[\"Gender\"] = sub\n",
    "trn, sub = target_encode(trn_df[\"Country\"], \n",
    "                         sub_df[\"Country\"], \n",
    "                         target=trn_df['Total Yearly Income [EUR]'], \n",
    "                         min_samples_leaf=100,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.01)\n",
    "trn.head(10)\n",
    "trn_df[\"Country\"] = trn\n",
    "sub_df[\"Country\"] = sub\n",
    "trn, sub = target_encode(trn_df[\"Profession\"], \n",
    "                         sub_df[\"Profession\"], \n",
    "                         target=trn_df['Total Yearly Income [EUR]'], \n",
    "                         min_samples_leaf=100,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.01)\n",
    "trn.head(10)\n",
    "trn_df[\"Profession\"] = trn\n",
    "sub_df[\"Profession\"] = sub\n",
    "trn, sub = target_encode(trn_df[\"University Degree\"], \n",
    "                         sub_df[\"University Degree\"], \n",
    "                         target=trn_df['Total Yearly Income [EUR]'], \n",
    "                         min_samples_leaf=100,\n",
    "                         smoothing=10,\n",
    "                         noise_level=0.01)\n",
    "trn.head(10)\n",
    "trn_df[\"University Degree\"] = trn\n",
    "sub_df[\"University Degree\"] = sub\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = trn_df.drop(['Total Yearly Income [EUR]'], axis=1)\n",
    "y = trn_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XTrain_final = X\n",
    "XTest_final = sub_df\n",
    "YTrain_final = y\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating test and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain,xValidation,yTrain,yValidation = train_test_split(XTrain_final,YTrain_final,test_size=0.2,random_state=1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating LightGBM input matrix\n",
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(xTrain, label=yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining parameter\n",
    "params = {'max_depth': 20, 'learning_rate': 0.002, \"boosting\": \"gbdt\", \"bagging_seed\": 11, \"metric\": 'mae', \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Model\n",
    "clf = lgb.train(params, d_train, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting validation set\n",
    "y_predicted = clf.predict(xValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(yValidation, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_csv(\"tcd-ml-1920-group-income-test.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predidicting Kaggle Test data\n",
    "y_predicted = clf.predict(XTest_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating submission File\n",
    "submission = pd.DataFrame()\n",
    "submission['Instance'] = test1['Instance']\n",
    "submission['Total Yearly Income [EUR]'] = y_predicted\n",
    "submission.to_csv(\"LightGBM_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
